# Formula_One_Data_Engineering

This project was developed during a Data Engineering/Analysis internship to build an ETL (Extract, Transform, Load) pipeline for Formula 1 data. It processes data from CSV files and the Ergast F1 API, transforming it into a structured format and loading it into a PostgreSQL database designed with a Snowflake schema. The pipeline uses Apache Kafka for simulating real-time data ingestion, Apache Airflow for workflow orchestration, and Docker for containerized deployment. After loading, the data is analyzed and visualized using Power BI to create insights like driver performance, constructor standings, and race statistics.

 ![unnamed](https://github.com/user-attachments/assets/3601e70e-3d9d-4a06-8b11-3b69fec2b492)
 ![unnamed-1](https://github.com/user-attachments/assets/9283ca3a-9a23-4e6c-85e9-7b83f657bf05)
 ![unnamed](https://github.com/user-attachments/assets/e7c7fd0f-146b-446d-b352-bd16c9ebcf54)
 ![unnamed-1](https://github.com/user-attachments/assets/95d3cb2f-c549-4d07-b0bc-b41ad67392c2)




